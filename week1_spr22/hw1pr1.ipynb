{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### week1 ~ the-web-as-filesystem...  &nbsp;&nbsp; (hw1pr1.ipynb)\n",
    "\n",
    "[the google doc with hw1's details](https://docs.google.com/document/d/11ALzpsANe3ZDR5sk8-kgaElaX_fwlDINVlQ8WS8JfQE/edit)\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1:  Traversing the world - and web - without a browser.   \n",
    "\n",
    "<b>Using the ISS + USGS APIs</b> \n",
    "\n",
    "(hw1pr1.ipynb)\n",
    "\n",
    "+ Here, you'll make sure you have the `requests` library and then you'll\n",
    "+ make some calls using `requests` to International Space Station API and the US Geological Survey's earthquake API\n",
    "+ \"API\" is short for \"Application Programming Interface\" \n",
    "  + Admittedly, this is not a very informative name, even fully expanded!\n",
    "  + The API refers to the set of services, usually functions and/or urls, provided by some software (or site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# see if you have the requests library\n",
    "#\n",
    "\n",
    "from pip._vendor import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# If you _don't_ have the requests library, let's install it!\n",
    "#\n",
    "\n",
    "# for me, it worked to uncomment and run this command, here in this cell:\n",
    "#!pip3 install requests  OR    !pip install requests \n",
    "\n",
    "# an alternative is to run, in a terminal, the command  \n",
    "#  pip3 install requests  OR    pip install requests   (the ! is needed only if inside Python)\n",
    "\n",
    "# however, the \"restart\" button (with the loop-arrow) \n",
    "#  was _not_ enough for my notebook to recognize the library installed\n",
    "\n",
    "# for me, I had to (1) disable + re-enable the jupyter extension\n",
    "# then, (2) disable + re-enable the python extension\n",
    "# which was enough to now \"see\" the newly installed library\n",
    "\n",
    "# \n",
    "# My hunch is that some systems will need a full vscode shutdown/restart...\n",
    "# The _Python: Select Interpreter_ command sems to help when it can find no kernels...\n",
    "# That command can be accessed with command-shift-p (Mac) or control-shift-p (Win)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hopefully, this now works! (if so, it will succeed silently)\n",
    "#\n",
    "\n",
    "from pip._vendor import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it with the International Space Station api at [http://api.open-notify.org/iss-now.json](http://api.open-notify.org/iss-now.json)\n",
    "+ [This page has documentation on the ISS API](http://open-notify.org/Open-Notify-API/ISS-Location-Now/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# we assign the url and obtain the api-call result into result\n",
    "#    Note that result will be an object that contains many fields (not a simple string)\n",
    "# \n",
    "\n",
    "url = \"http://api.open-notify.org/iss-now.json\"\n",
    "result = requests.get(url)\n",
    "result    \n",
    "\n",
    "# if it succeeded, you should see <Response [200]>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pip._vendor.requests.models.Response"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# when exploring, you'll often obtain an unfamiliar object. \n",
    "# Here, we'll ask what type it is \n",
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__attrs__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_content', '_content_consumed', '_next', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Here, we'll ask what fields it contains:  \n",
    "#       dir(ob) returns Python's \"directory\" of fields available in the object ob\n",
    "print(dir(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result.url is http://api.open-notify.org/iss-now.json\n",
      "result.raw is <pip._vendor.urllib3.response.HTTPResponse object at 0x10d7b3b20>\n",
      "result.encoding is None\n",
      "result.status_code is 200\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's try printing a few of those fields: \n",
    "print(f\"result.url is {result.url}\")  # the original url\n",
    "print(f\"result.raw is {result.raw}\")  # another object!\n",
    "print(f\"result.encoding is {result.encoding}\")  # utf-8 is very common\n",
    "print(f\"result.status_code is {result.status_code}\")  # 200 is success!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'message': 'success', 'iss_position': {'longitude': '47.3613', 'latitude': '-42.1011'}, 'timestamp': 1643838440}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In this case, we know the result is a JSON file, and we can obtain it:\n",
    "json_contents = result.json()\n",
    "print(json_contents)\n",
    "\n",
    "# json is a javascript dictionary, which is (almost) the same as a Python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['message', 'iss_position', 'timestamp']\n",
      "json_contents['iss_position'] is {'longitude': '47.3613', 'latitude': '-42.1011'}\n",
      "['longitude', 'latitude']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# In Python, we can use the resulting dictionary... let's see its keys:\n",
    "print(list(json_contents.keys()))  \n",
    "\n",
    "# it has three keys :-)   Let's see the value for the key 'iss_position':\n",
    "print(f\"json_contents['iss_position'] is {json_contents['iss_position']}\")\n",
    "\n",
    "# It's another dictionary!  Let's give it a name -- and then look at its keys!\n",
    "val = json_contents['iss_position']\n",
    "print(list(val.keys()))     # it has the lat and long!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ISS's longitude is -42.1011\n",
      "The ISS is 76.1978째 away from Claremont, latitudinally!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Notice that obtaining a specific piece of data may involve \"digging\" into the structure.\n",
    "# Here's the latitude of the ISS:\n",
    "val = json_contents['iss_position']\n",
    "print(f\"The ISS's longitude is {val['latitude']}\")\n",
    "\n",
    "# this is a string... if we want to compute with it, we'll need to convert to a numeric type!\n",
    "lat = float(val['latitude']) \n",
    "claremont_lat = 34.0967\n",
    "print(f\"The ISS is {abs(lat - claremont_lat)}째 away from Claremont, latitudinally!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ISS is 70.3585째 away from Claremont, longitudally!\n",
      "The ISS is closer to Claremont longitudally!\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Your task!     (Task #1)\n",
    "#\n",
    "\n",
    "#\n",
    "# Continue the above reasoning to compute \n",
    "# (a) how many degrees of longitude the ISS is away from Claremont\n",
    "long = float(val['longitude']) \n",
    "claremont_long = 117.7198\n",
    "print(f\"The ISS is {abs(long - claremont_long)}째 away from Claremont, longitudally!\")\n",
    "\n",
    "# (b) whether the ISS is closer to Claremont, longitudinally or latitudinally\n",
    "lat = float(val['latitude']) \n",
    "claremont_lat = 34.0967\n",
    "ISS_lat_difference = lat-claremont_lat\n",
    "ISS_long_difference = long-claremont_long\n",
    "# a greater difference means a further distance!\n",
    "if abs(ISS_lat_difference) > abs(ISS_long_difference):\n",
    "    print(\"The ISS is closer to Claremont longitudally!\")\n",
    "else:\n",
    "    print(\"The ISS is closer to Claremont latitudally!\")\n",
    "\n",
    "# (c) extra: estimate how many _miles_ away the ISS is from you right now...  \n",
    "#            (this will require some extra web-searching and estimating! :-)\n",
    "# maybe we will do this...maybe we won't\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not every url returns json data!\n",
    "+ The url [https://www.cs.hmc.edu/~dodds/demo.html](https://www.cs.hmc.edu/~dodds/demo.html) returns a plain-text file with _markup_ text\n",
    "+ that is to say, with HTML tags, such as `<title>Title</title>` to designate the components of its content\n",
    "+ HTML stands for _hypertext markup language_   \n",
    "+ Often anything with tags similar to `<b>be bold!</b>` is called \"markup.\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "len(text) is 722\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# here, we will obtain plain-text results from a request\n",
    "url = \"https://www.cs.hmc.edu/~dodds/demo.html\"  # try it + source\n",
    "#url = \"https://www.webb.org/\"  # try it + source\n",
    "result = requests.get(url)        \n",
    "print(f\"result is {result}\")        # hopefully it's 200\n",
    "text = result.text                  # provides the HTML page as a large string...\n",
    "print(f\"len(text) is {len(text)}\")  # let's see how large the HTML page is... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 42 characters are\n",
      "\n",
      "<html>\n",
      "  <head>\n",
      "    <title>My streamlined \n"
     ]
    }
   ],
   "source": [
    "print(\"The first 42 characters are\\n\")\n",
    "print(text[:42])                  # we'll print the first few characters...  \n",
    "\n",
    "# change this to text[:] to see the whole document...\n",
    "# Notice that we can run many different analyses without having to re-call/re-scrape the page (this is good!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### But, we're going to focus on json-providing API calls for now \n",
    "+ for pr1 and pr2, at least, we'll use json\n",
    "+ pr3 has the _option_ of using BeautifulSoup to parse raw html (up to you)\n",
    "+ Next are anotehr example api call to the ISS (to obtain the current astronaut-list), and\n",
    "+ An api call to the USGS, for earthquake data\n",
    "+ Below, you'll use earthquake data to investigate seismic activity for you choice of place...\n",
    "+   ... summarizing over quake-magnitude, areas-of-relevance, and different months\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# json takes some getting used to!\n",
    "# \n",
    "\n",
    "# These two json files (really dictionaries) are the first of this week's two \"quizzes\" (in-class exercises)\n",
    "\n",
    "#\n",
    "# Task #2:    try out the following examples, with an \"ear\" toward digesting what's going on...\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the url used was http://api.open-notify.org/astros.json\n",
      "json_contents.keys() are ['people', 'message', 'number']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# The astros!       http://api.open-notify.org/astros.json\n",
    "\n",
    "url = \"http://api.open-notify.org/astros.json\"\n",
    "result = requests.get(url)\n",
    "print(f\"result is {result}\")     # we will hope for a 200\n",
    "print(f\"the url used was {result.url}\")   # let's see the url again...\n",
    "json_contents = result.json()    # would throw an exception/error, if it were not json...  \n",
    "print(f\"json_contents.keys() are {list(json_contents.keys())}\")\n",
    "\n",
    "#\n",
    "# It's best to separate the obtaining of the data from its analysis.\n",
    "#   otherwise, you might accidentally obtain the data too often, \n",
    "#   angering the data-provider, who can stop listening to you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'people': [{'craft': 'ISS', 'name': 'Mark Vande Hei'}, {'craft': 'ISS', 'name': 'Pyotr Dubrov'}, {'craft': 'ISS', 'name': 'Anton Shkaplerov'}, {'craft': 'Shenzhou 13', 'name': 'Zhai Zhigang'}, {'craft': 'Shenzhou 13', 'name': 'Wang Yaping'}, {'craft': 'Shenzhou 13', 'name': 'Ye Guangfu'}, {'craft': 'ISS', 'name': 'Raja Chari'}, {'craft': 'ISS', 'name': 'Tom Marshburn'}, {'craft': 'ISS', 'name': 'Kayla Barron'}, {'craft': 'ISS', 'name': 'Matthias Maurer'}], 'message': 'success', 'number': 10}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# The astros as a json structure (dictionary)\n",
    "d = json_contents\n",
    "\n",
    "# equivalently,\n",
    "# d = {\"people\": [{\"craft\": \"ISS\", \"name\": \"Mark Vande Hei\"}, {\"craft\": \"ISS\", \"name\": \"Pyotr Dubrov\"}, {\"craft\": \"ISS\", \"name\": \"Anton Shkaplerov\"}, {\"craft\": \"Shenzhou 13\", \"name\": \"Zhai Zhigang\"}, {\"craft\": \"Shenzhou 13\", \"name\": \"Wang Yaping\"}, {\"craft\": \"Shenzhou 13\", \"name\": \"Ye Guangfu\"}, {\"craft\": \"ISS\", \"name\": \"Raja Chari\"}, {\"craft\": \"ISS\", \"name\": \"Tom Marshburn\"}, \n",
    "# {\"craft\": \"ISS\", \"name\": \"Kayla Barron\"}, {\"craft\": \"ISS\", \"name\": \"Matthias Maurer\"}], \"message\": \"success\", \"number\": 10}\n",
    "\n",
    "d           # this plain-value formats more neatly than print(d)\n",
    "print(d)    # this look illustrates how nice it is to have a scripting language interpret things!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'craft': 'ISS', 'name': 'Anton Shkaplerov'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# let's explore d...  Can we access 'Raja'?\n",
    "d[\"people\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0 is Mark Vande Hei on the ISS\n",
      "Item 1 is Pyotr Dubrov on the ISS\n",
      "Item 2 is Anton Shkaplerov on the ISS\n",
      "Item 3 is Zhai Zhigang on the Shenzhou 13\n",
      "Item 4 is Wang Yaping on the Shenzhou 13\n",
      "Item 5 is Ye Guangfu on the Shenzhou 13\n",
      "Item 6 is Raja Chari on the ISS\n",
      "Item 7 is Tom Marshburn on the ISS\n",
      "Item 8 is Kayla Barron on the ISS\n",
      "Item 9 is Matthias Maurer on the ISS\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's loop over all of the names:\n",
    "N = len(d[\"people\"])\n",
    "\n",
    "for i in range(N):  # loop over each index of d[\"people\"]\n",
    "    craft = d[\"people\"][i][\"craft\"]\n",
    "    person = d[\"people\"][i][\"name\"]\n",
    "    print(f\"Item {i} is {person} on the {craft}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### Earthquake data\n",
    "[Here is the USGS Earthquate data API documentation](https://earthquake.usgs.gov/fdsnws/event/1/)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result is <Response [200]>\n",
      "the full url used was\n",
      " https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2022-01-23&endtime=2022-01-26&minmagnitude=5.6\n",
      "json_contents.keys() are ['type', 'metadata', 'features', 'bbox']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# The quakes!   https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&minmagnitude=5.6&starttime=2022-01-23&endtime=2022-01-26\n",
    "\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "# note that this is much shorter than the above full url...\n",
    "# that latter half consists of parameters to the API call...\n",
    "# the parameters are documented here: \n",
    "#     https://earthquake.usgs.gov/fdsnws/event/1/#parameters\n",
    "\n",
    "# for three of the parameters, let's use variables:\n",
    "min_mag = 5.6               # the minimum magnitude considered a quake (min_mag)\n",
    "start_time = \"2022-01-23\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2022-01-26\"  # similar for the end\n",
    "\n",
    "# we assemble a dictionary of our parameters, named param_d\n",
    "# there are many more parameters available. The problems below ask you to explore them...\n",
    "param_d = {  \"format\":\"geojson\",         # this is simply hard-coded to obtain json\n",
    "             \"starttime\":start_time,\n",
    "             \"endtime\":finish_time,\n",
    "             \"minmagnitude\":min_mag,\n",
    "          }\n",
    "\n",
    "result = requests.get(url, params=param_d)     # a named input, params, taking the value param_d, above\n",
    "print(f\"result is {result}\")                   # hopefully, this is 200\n",
    "print(f\"the full url used was\\n {result.url}\")   # this includes the parameters!\n",
    "json_contents = result.json()    # would throw an exception/error, if it were not json...  \n",
    "print(f\"json_contents.keys() are {list(json_contents.keys())}\")\n",
    "\n",
    "#\n",
    "# It's best to separate the obtaining of the data from its analysis.\n",
    "#   otherwise, you might accidentally obtain the data too often, \n",
    "#   angering the data-provider, who can stop listening to you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# The quakes as a json structure (dictionary)\n",
    "d = json_contents\n",
    "\n",
    "d    # this plain-value formats more neatly than print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# let's explore:\n",
    "print(f'len(d[\"features\"]) is {len(d[\"features\"])}')\n",
    "\n",
    "i = 0\n",
    "d[\"features\"][i][\"properties\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0 was in this place: South Sandwich Islands region\n",
      "Item 1 was in this place: 152 km S of Laojunmiao, China\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# with the structure, we can loop over them, extracting what we want, e.g., place:\n",
    "\n",
    "# loop over them\n",
    "N = len(d[\"features\"])\n",
    "for i in range(N):\n",
    "    print(f'Item {i} was in this place: {d[\"features\"][i][\"properties\"][\"place\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/query\"\n",
    "\n",
    "# param vairables\n",
    "min_mag = 3.2              \n",
    "start_time = \"2020-01-23\"  \n",
    "finish_time = \"2022-01-26\"  \n",
    "latitude = 34.0967\n",
    "longitude = -117.7198 \n",
    "rad_list = [200, 500, 1000] \n",
    "\n",
    "rad_all_jsons = {}\n",
    "\n",
    "for rad in rad_list:\n",
    "    param_d = {  \"format\":\"geojson\",         \n",
    "             \"starttime\":start_time,\n",
    "             \"endtime\":finish_time,\n",
    "             \"minmagnitude\":min_mag,\n",
    "             \"latitude\":latitude,\n",
    "             \"longitude\":longitude,\n",
    "             \"maxradiuskm\":rad\n",
    "          }\n",
    "\n",
    "    result = requests.get(url, params=param_d)\n",
    "    print(f\"for radius {rad} the result is {result}\")                   \n",
    "    print(f\"the full url used was\\n {result.url}\")  \n",
    "    json_contents = result.json()  \n",
    "    rad_all_jsons[rad] = json_contents  \n",
    "\n",
    "    print(f\"json_contents.keys() are {list(json_contents.keys())}\")\n",
    "    \n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) a correspondingly larger text-formatted table of seismic activity (for Claremont, to start...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'| {\"-- Claremont-ally --\":^25s} |')              \n",
    "print(f'|   {\"mag\":>10s} ~ {\"radius\":>8s}   |') \n",
    "#3 rads of 200, 500, 1000 \n",
    "for rad in rad_all_jsons:\n",
    "    #lets print 5 maxMagnitudes per each rad\n",
    "    i =0\n",
    "    while i < 5:\n",
    "        current_radius = rad  \n",
    "        current_mag = rad_all_jsons[rad]['features'][i]['properties']['mag'] #index into mag value w i limit to 5 per rad \n",
    "        print(f\"|   {current_mag:>10.2f} ~ {current_radius:>8d}   |\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) the same larger table for another place (lat/long) of your choice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latitude = 3.4653\n",
    "longitude = 62.2159\n",
    "rad_all_jsons = {}\n",
    "\n",
    "for rad in rad_list:\n",
    "    param_d = {  \"format\":\"geojson\",         \n",
    "             \"starttime\":start_time,\n",
    "             \"endtime\":finish_time,\n",
    "             \"minmagnitude\":min_mag,\n",
    "             \"latitude\":latitude,\n",
    "             \"longitude\":longitude,\n",
    "             \"maxradiuskm\":rad\n",
    "          }\n",
    "\n",
    "    result = requests.get(url, params=param_d)                \n",
    "    json_contents = result.json()  \n",
    "    rad_all_jsons[rad] = json_contents \n",
    "\n",
    "print(f'| {\"-- Amazon Rainforest --\":^25s} |')              \n",
    "print(f'|   {\"mag\":>10s} ~ {\"radius\":>8s}   |') \n",
    "#3 rads of 200, 500, 1000 \n",
    "for rad in rad_all_jsons:\n",
    "    #lets print 5 maxMagnitudes per each rad\n",
    "    i =0\n",
    "    while i < 5:\n",
    "        current_radius = rad  \n",
    "        current_mag = rad_all_jsons[rad]['features'][i]['properties']['mag'] #index into mag value w i limit to 5 per rad \n",
    "        print(f\"|   {current_mag:>10.2f} ~ {current_radius:>8d}   |\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) a measurement-value (\"metric\") of your own design, of \"seismic volatility\"\n",
    "\n",
    "alert  level!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_mag = 3.2, the result is <Response [200]>\n",
      "the full url used was https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2020-01-23&endtime=2022-01-26&alertlevel=red\n",
      "\n",
      "|     -- Red Levels --      |\n",
      "|          mag ~    place   |\n",
      "|         6.40 ~     Iran   |\n",
      "|         5.40 ~    China   |\n",
      "|         7.00 ~   Mexico   |\n",
      "|         7.20 ~    Haiti   |\n",
      "|         6.00 ~    India   |\n"
     ]
    }
   ],
   "source": [
    "           \n",
    "start_time = \"2020-01-23\"  \n",
    "finish_time = \"2022-01-26\"  \n",
    "alert_list = ['red']      #new measure!!!\n",
    "\n",
    "all_jsons = {}  \n",
    "\n",
    "for alert in alert_list:   \n",
    "\n",
    "    param_d = { \"format\":\"geojson\",      \n",
    "                \"starttime\":start_time,\n",
    "                \"endtime\":finish_time,\n",
    "                \"alertlevel\":alert\n",
    "            }\n",
    "\n",
    "    result = requests.get(url, params=param_d)    \n",
    "    print(f\"for min_mag = {min_mag}, the result is {result}\")                   \n",
    "    print(f\"the full url used was {result.url}\")  \n",
    "    json_contents = result.json()    \n",
    "    all_jsons[alert] = json_contents   \n",
    "    print()\n",
    "    time.sleep(0.1)   \n",
    "\n",
    "\n",
    "print(f'| {\"-- Red Levels --\":^25s} |')              \n",
    "print(f'|   {\"mag\":>10s} ~ {\"place\":>8s}   |') \n",
    "\n",
    "i =0    \n",
    "while i < 5:\n",
    "    current_place = all_jsons['red']['features'][i]['properties']['place']\n",
    "    current_place =  current_place.split(\",\")[-1]\n",
    "    current_mag = all_jsons['red']['features'][i]['properties']['mag'] \n",
    "    print(f\"|   {current_mag:>10.2f} ~ {current_place:>8s}   |\")\n",
    "    i+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) answer which of Claremont + your other spot is more \"seismically volatile\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the result is <Response [400]>\n",
      "the full url used was https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime=2020-01-23&endtime=2022-01-26&latitude=34.0967&longitude=-117.7198&alertlevel=red\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Input \u001b[0;32mIn [230]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe result is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)                   \n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe full url used was \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m---> 24\u001b[0m json_contents \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages/pip/_vendor/requests/models.py:898\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[1;32m    893\u001b[0m             \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[1;32m    894\u001b[0m             \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[1;32m    895\u001b[0m             \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[1;32m    896\u001b[0m             \u001b[38;5;66;03m# used.\u001b[39;00m\n\u001b[1;32m    897\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "coordinates ={}\n",
    "coordinates['claremont'] = [34.0967, -117.7198]\n",
    "coordinates['rainforest'] = [3.4653, 62.2159]\n",
    "\n",
    "\n",
    "start_time = \"2020-01-23\"  \n",
    "finish_time = \"2022-01-26\"  \n",
    "alert_list = ['red']      \n",
    "\n",
    "\n",
    "for place in coordinates:   \n",
    "\n",
    "    param_d = { \"format\":\"geojson\",      \n",
    "                \"starttime\":start_time,\n",
    "                \"endtime\":finish_time,\n",
    "                \"latitude\": coordinates[place][0],\n",
    "                \"longitude\":coordinates[place][-1],\n",
    "                \"alertlevel\":alert\n",
    "            }\n",
    "\n",
    "    result = requests.get(url, params=param_d)    \n",
    "    print(f\"the result is {result}\")                   \n",
    "    print(f\"the full url used was {result.url}\")  \n",
    "    json_contents = result.json()     \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) answer which _month_ is the most seismically volatile (your choice of location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for min_mag = 2.42, the result is <Response [200]>\n",
      "the full url used was https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&starttime=2022-01-01&endtime=2022-01-31&minmagnitude=2.42\n",
      "json_contents is {'count': 1744, 'maxAllowed': 20000}\n",
      "for min_mag = 4.42, the result is <Response [200]>\n",
      "the full url used was https://earthquake.usgs.gov/fdsnws/event/1/count?format=geojson&starttime=2022-01-01&endtime=2022-01-31&minmagnitude=4.42\n",
      "json_contents is {'count': 584, 'maxAllowed': 20000}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# This example uses a different API:     https://earthquake.usgs.gov/fdsnws/event/1/count\n",
    "#\n",
    "\n",
    "import time\n",
    "url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "\n",
    "# the parameters are documented here: \n",
    "#     https://earthquake.usgs.gov/fdsnws/event/1/#parameters\n",
    "\n",
    "# we will be more ambitious with our API calls and parameters:\n",
    "min_mag_list = [2.42, 4.42]      # now, a list of these!\n",
    "start_time = \"2022-01-01\"   # this is the year-month-day format of the start\n",
    "finish_time = \"2022-01-31\"  # similar for the end\n",
    "\n",
    "all_jsons = {}  # an empty dictionary, to hold all of the resulting jsons...\n",
    "\n",
    "# This time, we loop over our different min-magnitudes\n",
    "for min_mag in min_mag_list:   # element-by-element looping, not index-based looping\n",
    "\n",
    "    param_d = { \"format\":\"geojson\",         # this is simply hard-coded\n",
    "                \"starttime\":start_time,\n",
    "                \"endtime\":finish_time,\n",
    "                \"minmagnitude\":min_mag,\n",
    "            }\n",
    "\n",
    "    result = requests.get(url, params=param_d)     # a named input, params, taking the value param_d, above\n",
    "    print(f\"for min_mag = {min_mag}, the result is {result}\")                   # hopefully, this is 200\n",
    "    print(f\"the full url used was {result.url}\")   # this includes the parameters!\n",
    "    json_contents = result.json()    \n",
    "    all_jsons[min_mag] = json_contents    # STORE INTO OUR STRUCTURE, named all_jsons\n",
    "    print(f\"json_contents is {json_contents}\")\n",
    "    time.sleep(0.1)                       # polite!\n",
    "\n",
    "#\n",
    "# It's best to separate the obtaining of the data from its analysis.\n",
    "#   otherwise, you might accidentally obtain the data too often, \n",
    "#   angering the data-provider, who can stop listening to you..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|      -- globally --       |\n",
      "|      min_mag ~    count   |\n",
      "|         2.42 ~     1744   |\n",
      "|         4.42 ~      584   |\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# A starter table, with the two json results now in all_jsons\n",
    "#\n",
    "\n",
    "print(f'| {\"-- globally --\":^25s} |')                # ^ means \"center\"\n",
    "print(f'|   {\"min_mag\":>10s} ~ {\"count\":>8s}   |')   # > means \"right justify\"\n",
    "for min_mag in all_jsons:                            # loop over the keys, which are the min_mag floats\n",
    "    current_json = all_jsons[min_mag]                # get the current json result\n",
    "    current_count = current_json['count']            # obtain its count value\n",
    "    print(f\"|   {min_mag:>10.2f} ~ {current_count:>8d}   |\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ccb4bb6bd67730c9185e6c24c983362cd7b4575b595bfae100d8d91e48f4f1e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
